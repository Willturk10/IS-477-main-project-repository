Overview: The overarching goal of my project is to see if different government programs that give incentives for things such as solar panels and electric car purchases are working to the extent it was planned. I will look primarily at solar panels as information on solar panels is the easiest to find consistent data on. I will research different datasets with such information to discover trends to help answer questions about the effectiveness of different municipal programs that offer rebates for residential solar panel installation specifically.

Research Question(s): 
1. In neighborhoods or areas with a significant percentage of houses with rebates, is there a sizable drop in the amount of electricity this neighborhood or area uses from the greater grid?

2. What demographic and/or housing factors have the strongest correlation with a household getting a rebate for solar panels?

Team: Since I am working alone I will do every step.

Datasets: 1. HUD USPS Vacancy dataset. This is a dataset that specifically shows vacant houses as identified by the USPS. This will be relevant when examining the power that different areas pull from the greater electric grid as we need to factor in empty houses in an area.

2. Energy Information Administration- Electric Power sales, revenue, and energy efficiency form dataset. This contains information from utility companies on retail sales of electricity, customer insight data, revenue information and more.

3. U.S. census dataset(American Community Survey). This contains very detailed population and housing information for areas throughout the country. It also has information pertaining to things like income, education, and race.



Timeline: Week 1: Acquire three distinct datasets from trustworthy sources, a HUD USPS Vacancy dataset, a energy Information Administration- Electric Power sales, revenue, and energy efficiency form dataset, and a U.S. census dataset.  After this, ethical handling will identify privacy and licensing constraints for this data.

Week 2:
A storage strategy using a currently unknown relational database will be the next thing to create. The ethical data handling review will be finished and will show how privacy, copyright, and terms of use are addressed. The acquired datasets will be loaded into the main database, assuming everything goes well.

Week 3-4: We will then perform data integration to try and join the datasets. An initial data quality assessment will be documented, profiling completeness and consistency. The exact process for this is currently unknown and a solution is actively being brainstormed.

Week 5-6: After this, we will use data cleaning methods to change any missing values from any possible errors on the way. The next part of the workflow process will begin by starting the extraction, integration, and cleaning scripts into one area, hopefully.

Week 6-7:  The next step will be to test the overall end to end workflow. With this new and clean data, we will proceed to any modeling and evaluation questions that can be answered. The main thing after that will be to fully document the data and to create a dictionary for our new data.

Week 8: The final thing to do is to make sure the gitHub repository contains all code and everything that needs to be included in the final version of the project The goal is to create a fully reproducible research package.






Constraints: The datasets we have chosen may take time to convert to a size that can be compatible with my computer's processing capabilities. I also might need to refine my research question further so that I know what to specifically be looking for when I begin to look for trends.

Gaps: As of right now there are no foreseeable gaps except for making sure all the datasets can align and be compared adequately. I will make sure to prioritize this immediately as this is essential to answering our various research questions.
